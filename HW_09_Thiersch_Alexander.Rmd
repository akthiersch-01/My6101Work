---
title: "Intro to DS - Logit Regression"
author: ""
# date: "today"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: hide
    number_sections: false
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
---

```{r init, include=FALSE}
# some of common options (and the defaults) are: 
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right', 
library(ezids)
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = F, results = "hide", message = F)
options(scientific=T, digits = 3) 
# options(scipen=9, digits = 3) 
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
```

# HW Assignment - Logit Regression

We have the historic Titanic dataset to study here. The version presented has these variables: 

* `survival`: Survival,	0 = No, 1 = Yes
* `pclass`: Ticket class, 1 = 1st, 2 = 2nd, 3 = 3rd
* `sex`: Gender / Sex
* `age`: Age in years
* `sibsp`: # of siblings / spouses on the Titanic
* `parch`: # of parents / children on the Titanic
* `ticket`: Ticket number (for superstitious ones)
* `fare`: Passenger fare
* `embarked`: Port of Embarkment	C: Cherbourg, Q: Queenstown, S: Southampton

The questions listed here are the basic guidelines, not the only goal, in this homework. For example, after you load the dataframe, even though the question does not ask you to look at the structure of the dataframe, you most likely should. You are given less and less “specific to-dos” in the homework, as you are getting more familiar with the data analytic process. Calculate and figure out the necessary info needed in the analysis, even though the questions might not ask for them explicitly. When you look at your own work, you should find it convincing, answering the questions and technically sound.  


## Titanic Tragedy Dataset  

### Question 1

**Import the dataset into R**  
Import the dataset into R, and call it titanic_orig, and explore it little to get the overall picture of the dataset. Eventually we would like to see what affected survival in the tragedy.  
```{r}
library(readr)
library(tidyr)
library("regclass")
library("ResourceSelection")
library("pROC")
library(kableExtra)
titanic_orig <- read_csv("/Users/akthiersch/Desktop/Datasets/Titanic.csv")
#View(titanic_orig)



```


### Question 2 
**Age**  
One of the main factors we will try is Age. How many missing values are there for the variable `age`? If not too many, we should just clean those up and subset those out.  

There are a total of 177 missing values for the variable age.

```{r}
sum(is.na(titanic_orig$age))

titanic_orig=titanic_orig %>% drop_na()

```


### Question 3  
**More clean up**  
While we are cleaning up the data, if we were to use sibsp and parch in our analysis, even though they are legitimately ratio level variables, we might not expect doubling the number of siblings necessarily double the effects on survival. For this reason, we should change these two variables to factor levels. Also change the other ones that you find imported as the wrong data type.  

The variables that were converted to factors include sibsp, parch, pclass, and survived.

```{r}
titanic_orig$sibsp=as.factor(titanic_orig$sibsp)

titanic_orig$parch=as.factor(titanic_orig$parch)

titanic_orig$pclass=as.factor(titanic_orig$pclass)

titanic_orig$survived=as.factor(titanic_orig$survived)

str(titanic_orig)

```

## Pre-logistic Regression

### Question 4  
**Survival and age**  
Before using our newly learned technique with logistic regression, let’s go old school, and use some prior knowledge to try find an answer. Does the data support that `age` very much affects `survival`?

The following two sampled t-test suggests that there is a statistically significant difference at the 5% significance level between the group means of passengers that survived and died. This is indicated by the low p-value of 0.03 which is lower than the 5% significance level critical value of 0.05.

```{r}
t.test_1<-t.test(age~survived, data=titanic_orig)

table_t.test <- data.frame(statisitc = c(t.test_1$statistic))
table_t.test <- rbind(table_t.test, t.test_1$parameter)
table_t.test <- rbind(table_t.test, t.test_1$p.value)
rownames(table_t.test) <- c("t", "df", "p-value")
table_t.test %>%
  kbl(caption="t-test: age~survived",
       format= "html", col.names = c(""),
      align="r") %>%
   kable_classic_2(full_width = F, html_font = "helvetica")



```


### Question 5  
**Survival and gender**  
Similarly, does the data support `sex` has an effect on `survival`? 

The following Chi-squared test suggests that sex and survival have a significant relationship due to the low p-value. This is because the p-value is <2e-16 which is smaller than the 5% critical value, indicating that the difference between the categorical variable is statistically significant at the 5% significance level.

```{r}
chisq.test_1<-chisq.test(titanic_orig$survived, titanic_orig$sex, correct=FALSE)

table_chisq.test_1 <- data.frame(statisitc = c(chisq.test_1$statistic))
table_chisq.test_1 <- rbind(table_chisq.test_1, chisq.test_1$parameter)
table_chisq.test_1 <- rbind(table_chisq.test_1, chisq.test_1$p.value)
rownames(table_chisq.test_1) <- c("X-Squared", "df", "p-value")
table_chisq.test_1 %>%
  kbl(caption="Chi-Squared Test: sex~survived",
       format= "html", col.names = c(""),
      align="r") %>%
   kable_classic_2(full_width = F, html_font = "helvetica")

```

### Question 6   
**Survival and pclass**  
Another big question is, does the data support Ticket class `pclass` has an effect on `survival`? 

The following Chi-squared test suggests that pclass and survival have a significant relationship due to the low p-value. This is because the p-value is <2e-16 which is smaller than the 5% critical value, indicating that the difference between the categorical variable is statistically significant at the 5% significance level.

```{r}
chisq.test_2<-chisq.test(titanic_orig$survived, titanic_orig$pclass, correct=FALSE)

table_chisq.test_2 <- data.frame(statisitc = c(chisq.test_2$statistic))
table_chisq.test_2 <- rbind(table_chisq.test_2, chisq.test_2$parameter)
table_chisq.test_2 <- rbind(table_chisq.test_2, chisq.test_2$p.value)
rownames(table_chisq.test_2) <- c("X-Squared", "df", "p-value")
table_chisq.test_2 %>%
  kbl(caption="Chi-Squared Test: pclass~survived",
       format= "html", col.names = c(""),
      align="r") %>%
   kable_classic_2(full_width = F, html_font = "helvetica")

```


## Logistic Regression

### Question 7   
**Survival and age + pclass**  
Now let us build a logit model with age+pclass as predictors, and analyze the results. Remember to do all the model evaluation steps. Is the model a good one?

The logit model has coefficients that are all statistically significant at the 5% significance level as indicated by the low p-values for each variables coefficients. The low p-value of the Holsem Test indicates that the model is a good fit for the data. Additionally, the area under the curve ROC value is 0.744, indicating that the model is a somewhat decent fit for the data but not the best fit because the value is not larger than 0.800. Finally, the McFadden psuedo-R-squared value for the model 0.142, indicating the model is not a good fit because the value is below 0.2. These goodness-of-fit values suggest that the model is a poor fit of the data.

```{r, results='asis'}
model1 <- glm(survived ~ age+pclass,data=titanic_orig,family="binomial")
table1<-summary(model1)

table1$coefficients %>%
  kbl(caption="Logit Regession: glm(survived ~ age + pclass)",
       format= "html", col.names = c("Estimate", "Std. Error", "z-value", "Pr(>|z|)"),
      align="r") %>%
   kable_classic_2(full_width = F, html_font = "helvetica")

#Confusion Matrix
xkabledply(confusion_matrix(model1), title = "Confusion matrix from Logit Model" )

#Hoslem Test
model1_Hoslem = hoslem.test(titanic_orig$survived, fitted(model1)) 

Hoslem_table1 <- data.frame(statisitc = c(model1_Hoslem$statistic))
Hoslem_table1 <- rbind(Hoslem_table1, model1_Hoslem$parameter)
Hoslem_table1 <- rbind(Hoslem_table1, model1_Hoslem$p.value)
rownames(Hoslem_table1) <- c("X-Squared", "df", "p-value")
Hoslem_table1 %>%
  kbl(caption="Hoslem Test: Model 1 glm(survived~age+pclass)",
       format= "html", col.names = c(""),
      align="r") %>%
   kable_classic_2(full_width = F, html_font = "helvetica")

#PROC
prob1=predict(model1, type = "response" )
titanic_orig$prob1=prob1
h <- roc(survived~prob1, data=titanic_orig)
auc(h) # area-under-curve prefer 0.8 or higher.
plot(h, main="Area Under the Curve Plot: Model 1 - Sensitivity v. Specificity")

#McFadden
model1_NullLogit <- glm(survived ~ 1, data = titanic_orig, family = "binomial")
mcFadden1 = 1 - logLik(model1)/logLik(model1_NullLogit)
mcFadden1


```


### Question 8  
**More features**  
Can we improve the model? Let us also throw in `sex` as a predictor. How’s the model now?

The logit model has coefficients that are all statistically significant at the 5% significance level as indicated by the low p-values for each variables coefficients. The low p-value of the Holsem Test indicates that the model is a good fit for the data. Additionally, the area under the curve ROC value is 0.851, indicating that the model is a good fit for the data because the value is larger than 0.800. Finally, the McFadden psuedo-R-squared value for the model 0.327, indicating the model is a decent fit because the value is close to 0.400. These goodness-of-fit values suggest that the model is a good fit for the data. This model is better than the previous model specifically because of the larger Holsem Test value.

```{r, results='asis'}
#Logit Model
model2 <- glm(survived ~ age+pclass+sex,data=titanic_orig,family="binomial")
table2<-summary(model2)

table2$coefficients %>%
  kbl(caption="Logit Regession: glm(survived ~ age + pclass + sex)",
       format= "html", col.names = c("Estimate", "Std. Error", "z-value", "Pr(>|z|)"),
      align="r") %>%
   kable_classic_2(full_width = F, html_font = "helvetica")

#Confusion Matrix
xkabledply(confusion_matrix(model2), title = "Confusion matrix from Logit Model" )

#Hosmer and Lemeshow test
model2_Hoslem = hoslem.test(titanic_orig$survived, fitted(model2)) 

Hoslem_table2 <- data.frame(statisitc = c(model2_Hoslem$statistic))
Hoslem_table2 <- rbind(Hoslem_table2, model2_Hoslem$parameter)
Hoslem_table2 <- rbind(Hoslem_table2, model2_Hoslem$p.value)
rownames(Hoslem_table2) <- c("X-Squared", "df", "p-value")
Hoslem_table2 %>%
  kbl(caption="Hoslem Test: Model 2 glm(survived~age+pclass+sex)",
       format= "html", col.names = c(""),
      align="r") %>%
   kable_classic_2(full_width = F, html_font = "helvetica")

#PROC
prob2=predict(model2, type = "response" )
titanic_orig$prob2=prob2
g <- roc(survived~prob2, data=titanic_orig)
auc(g) # area-under-curve prefer 0.8 or higher.
plot(g, main="Area Under the Curve Plot: Model 2 - Sensitivity v. Specificity")

#McFadden
model2_NullLogit <- glm(survived ~ 1, data = titanic_orig, family = "binomial")
mcFadden2 = 1 - logLik(model2)/logLik(model2_NullLogit)
mcFadden2


```



### Question 9  
**Sample Predictions**  
According to the last model, what is the chance of survival for a female, age 10, second class passenger? And a male, age 20, first class passenger?

## Interpretation  

The chance of survival for a female, age 10, second class passenger, is 2.098%. The chance of survival for a male, age 20, first class passenger, is 0.515%. These percentages suggest that females had a higher chance of survival than males when the titanic sank.

### Question 10  
*Summary*  
With all the results you obtained above, how would you present a high-level summary of the findings? Are the results surprising or expected? You might need to dig a little deeper than just the numbers, the test results/p-values, and the model statistics. This is a question about who we are, … in the face of death. 

The models and tests above suggest that the age, pclass, and sex variables are important to include in a logit regression that predict survivalist for passengers on the Titanic. In the the context of the Titanic, women and people of a wealthier ticket class had a higher chance of survival than males or those of a lower ticket class. Additionally, younger people also had a higher chance of survival than older people. These trends in serviceability are supported by the variable coefficients in each logit model, specifically Model 2. If I were reporting a high-level summary of my findings I would conclude that in the face of death, that passengers of a wealthier ticket class that were likely young and women were prioritized in escaping the sinking ship ensuring their survival. 



